{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP6M0iuD7Kbg"
      },
      "source": [
        "\n",
        "# ***Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8oJCaGg6fEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b95ca48-9726-44b1-bab1-8082c09f52cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "takgh2Ktitfb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import gc\n",
        "import imblearn\n",
        "from xml.etree import ElementTree\n",
        "from keras.utils import plot_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "\n",
        "import os\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "import colorsys\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from keras.models import load_model\n",
        "\n",
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "import json\n",
        "from xml.dom import minidom\n",
        "\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import glob\n",
        "from sklearn import metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.models as KM\n",
        "import keras.layers as KL\n",
        "from keras import backend as K\n",
        "import tensorflow.python.keras.engine  as ke\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "from config import Config\n",
        "import model as modellib\n",
        "import visualize\n",
        "from utils import Dataset\n",
        "from model import MaskRCNN\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fngih9EfVs9d"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(os.getcwd()+'/content/drive/MyDrive/Colab_Notebooks/VeDo_mrcnn/mrcnn_vedo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x7D7UGT7A_k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RxMJt03gbOw"
      },
      "source": [
        "# ***Functions***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr6b0Glt9R92"
      },
      "outputs": [],
      "source": [
        "def TopK(x, k):\n",
        "    a = dict([(i, j) for i, j in enumerate(x)])\n",
        "    sorted_a = dict(sorted(a.items(), key = lambda kv:kv[1], reverse=True))\n",
        "    indices = list(sorted_a.keys())[:k]\n",
        "    values = list(sorted_a.values())[:k]\n",
        "    return (indices, values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmbbVB4y9Wrh"
      },
      "outputs": [],
      "source": [
        "def class_val_func2():\n",
        "  imgpath = '/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset/images/'\n",
        "  annpath = '/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset/annots/'\n",
        "\n",
        "  n = 0\n",
        "  mae = 0\n",
        "  mse = 0\n",
        "  mses = []\n",
        "\n",
        "  for filename in listdir(imgpath):\n",
        "    image_id = filename.split('.')[0]\n",
        "\n",
        "    n += 1\n",
        "\n",
        "    img= plt.imread(imgpath + str(image_id) + \".jpg\")\n",
        "    result = mr_model_inf.detect([img])\n",
        "    r = result[0]\n",
        "\n",
        "    tree = ET.parse(annpath + str(image_id) +'.xml')\n",
        "    root = tree.getroot()\n",
        "\n",
        "    distance = float(root.find('./distance').text)\n",
        "\n",
        "    y = r['distance'][0]\n",
        "    mae += abs(y-distance)\n",
        "    mse += pow(y-distance,2)\n",
        "    mses.append(pow(y-distance,2))\n",
        "\n",
        "\n",
        "  return {\n",
        "      \"total\": n,\n",
        "      \"mae\": mae / n,\n",
        "      \"mse\": mse / n,\n",
        "      \"mses\": mses\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nscG43Id9bHM"
      },
      "outputs": [],
      "source": [
        "def custom_acc():\n",
        "  imgpath = '/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset/images/'\n",
        "  annpath = '/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset/annots/'\n",
        "\n",
        "  n = 0\n",
        "  s1 = 0\n",
        "  s2 = 0\n",
        "\n",
        "  for filename in listdir(imgpath):\n",
        "    image_id = filename.split('.')[0]\n",
        "\n",
        "    n += 1\n",
        "\n",
        "    img= plt.imread(imgpath + str(image_id) + \".jpg\")\n",
        "    result = mr_model_inf.detect([img])\n",
        "    r = result[0]\n",
        "\n",
        "    tree = ET.parse(annpath + str(image_id) +'.xml')\n",
        "    root = tree.getroot()\n",
        "\n",
        "    distance = float(root.find('./distance').text)\n",
        "\n",
        "    y = r['distance'][0]\n",
        "    if abs(y-distance) < 30:\n",
        "      s1 += 1\n",
        "    if abs(y-distance) < 15:\n",
        "      s2 += 1\n",
        "\n",
        "\n",
        "  return {\n",
        "      \"total\": n,\n",
        "      \"s1\": s1 / n,\n",
        "      \"s2\": s2 / n,\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KTAow619fuj"
      },
      "outputs": [],
      "source": [
        "def class_val_func():\n",
        "  imgpath = '/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset/images/'\n",
        "  annpath = '/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset/annots/'\n",
        "\n",
        "  n = 0\n",
        "  mae = 0\n",
        "  mse = 0\n",
        "\n",
        "  for filename in listdir(imgpath):\n",
        "    image_id = filename.split('.')[0]\n",
        "\n",
        "    n += 1\n",
        "\n",
        "    img= plt.imread(imgpath + str(image_id) + \".jpg\")\n",
        "    result = mr_model_inf.detect([img])\n",
        "    r = result[0]\n",
        "\n",
        "    tree = ET.parse(annpath + str(image_id) +'.xml')\n",
        "    root = tree.getroot()\n",
        "\n",
        "    distance = float(root.find('./distance').text)\n",
        "\n",
        "    y = r['distance'][0]\n",
        "    mae += abs(y-distance)\n",
        "    mse += pow(y-distance,2)\n",
        "\n",
        "\n",
        "  return {\n",
        "      \"total\": n,\n",
        "      \"mae\": mae / n,\n",
        "      \"mse\": mse / n,\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVTHH-GSpwVj"
      },
      "outputs": [],
      "source": [
        "def bb_intersection_over_union(boxA, boxB):\n",
        "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
        "\txA = max(boxA[0], boxB[0])\n",
        "\tyA = max(boxA[1], boxB[1])\n",
        "\txB = min(boxA[2], boxB[2])\n",
        "\tyB = min(boxA[3], boxB[3])\n",
        "\t# compute the area of intersection rectangle\n",
        "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
        "\t# compute the area of both the prediction and ground-truth\n",
        "\t# rectangles\n",
        "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "\t# compute the intersection over union by taking the intersection\n",
        "\t# area and dividing it by the sum of prediction + ground-truth\n",
        "\t# areas - the interesection area\n",
        "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "\t# return the intersection over union value\n",
        "\treturn iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUPDnO5p9j92"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_model(dataset, model):\n",
        "  imgpath = '/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset/images/'\n",
        "  annpath = '/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset/annots/'\n",
        "\n",
        "  n = 0\n",
        "  mae = 0\n",
        "  mse = 0\n",
        "  accuracy = 0\n",
        "  class_accuracy = 0\n",
        "  acc_ious = []\n",
        "  a_allboxes = []\n",
        "  p_allboxes = []\n",
        "  iousum=0\n",
        "\n",
        "  for image_id in dataset.image_ids:\n",
        "\n",
        "    img_info = dataset.image_info[image_id]\n",
        "    img= plt.imread(img_info['path'])\n",
        "    result = mr_model_inf.detect([img])\n",
        "    r = result[0]\n",
        "    pnames = r['class_ids'] - 1\n",
        "    scores = r['scores']\n",
        "    n += 1\n",
        "\n",
        "    tree = ET.parse(img_info['annotation'])\n",
        "    root = tree.getroot()\n",
        "    filename = str(root.find('./filename').text)[0:5]\n",
        "\n",
        "    names = []\n",
        "    for name in root.findall('./object/name'):\n",
        "      names.append(int(name.text))\n",
        "\n",
        "    if ((int(pnames[0])==names[0]) and int(pnames[1])==names[1]) or ((int(pnames[0])==names[1]) and int(pnames[1])==names[0]) :\n",
        "      class_accuracy +=2\n",
        "\n",
        "    aboxes = []\n",
        "    for box in root.findall('.//bndbox'):\n",
        "      xmin = int(box.find('xmin').text)\n",
        "      ymin = int(box.find('ymin').text)\n",
        "      xmax = int(box.find('xmax').text)\n",
        "      ymax = int(box.find('ymax').text)\n",
        "      coors = [xmin, ymin, xmax, ymax]\n",
        "      a_allboxes.append(coors)\n",
        "      aboxes.append(coors)\n",
        "\n",
        "    pboxes = r['rois']\n",
        "\n",
        "    pboxes[0][0],pboxes[0][1] = pboxes[0][1],pboxes[0][0]\n",
        "    pboxes[0][2],pboxes[0][3] = pboxes[0][3],pboxes[0][2]\n",
        "    pboxes[1][0],pboxes[1][1] = pboxes[1][1],pboxes[1][0]\n",
        "    pboxes[1][2],pboxes[1][3] = pboxes[1][3],pboxes[1][2]\n",
        "\n",
        "    if pboxes[0][0] > pboxes[1][0] and pboxes[0][1] > pboxes[1][1]:\n",
        "      pboxes[[0,1]] = pboxes[[1,0]]\n",
        "    p_allboxes.append(pboxes[0])\n",
        "    p_allboxes.append(pboxes[1])\n",
        "\n",
        "\n",
        "    iou1 = bb_intersection_over_union(pboxes[0],aboxes[0])\n",
        "    iou2 = bb_intersection_over_union(pboxes[1],aboxes[1])\n",
        "    acc_ious.append(iou1)\n",
        "    acc_ious.append(iou2)\n",
        "\n",
        "\n",
        "    distance = float(root.find('./distance').text)\n",
        "    distanceLabel = int(root.find('./distanceLabel').text)\n",
        "\n",
        "    if distanceLabel == int(r['distance_label']):\n",
        "      accuracy += 1\n",
        "    mae += abs(distance- float(r['distance']))\n",
        "    mse += pow(distance- float(r['distance']),2)\n",
        "\n",
        "  return {\n",
        "      \"number of samples\": n,\n",
        "      \"distance label accuracy\": accuracy / n,\n",
        "      \"distance mae\": mae/n,\n",
        "      \"distance mse\": mse/n,\n",
        "      \"class accuracy\": class_accuracy / (2*n),\n",
        "      \"bbox IoU\": np.mean(acc_ious)\n",
        "      }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcqD-vtZ9jRi"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"font.serif\"] = \"Times New Roman\"\n",
        "csfont = {'fontname':'DejaVu Serif'}\n",
        "def visualize(imageID):\n",
        "  # imgpath = '/content/drive/MyDrive/Workspace/Test-Images/'\n",
        "  # annpath = '/content/drive/MyDrive/Workspace/Test-Images/'\n",
        "  imgpath = '/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset/images/'\n",
        "  annpath = '/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset/annots/'\n",
        "\n",
        "  img= plt.imread(imgpath + str(imageID) + \".jpg\")\n",
        "  plt.figure(figsize=(5, 5),dpi=300)\n",
        "  plt.imshow(img)\n",
        "  result = mr_model_inf.detect([img])\n",
        "  r = result[0]\n",
        "\n",
        "  classes = r['class_ids']-1\n",
        "\n",
        "  # print(classes)\n",
        "\n",
        "  classNames = ['','']\n",
        "\n",
        "  if classes[0] ==0:\n",
        "      classNames[0] = 'balloon'\n",
        "  elif classes[0] ==1:\n",
        "      classNames[0] = 'bike'\n",
        "  elif classes[0] ==2:\n",
        "      classNames[0] = 'camel'\n",
        "  elif classes[0] ==3:\n",
        "      classNames[0] = 'car'\n",
        "  elif classes[0] ==4:\n",
        "      classNames[0] = 'helicopter'\n",
        "  elif classes[0] ==5:\n",
        "      classNames[0] = 'ladder'\n",
        "  elif classes[0] ==6:\n",
        "      classNames[0] = 'sofa'\n",
        "\n",
        "  if classes[1] ==0:\n",
        "      classNames[1] = 'balloon'\n",
        "  elif classes[1] ==1:\n",
        "      classNames[1] = 'bike'\n",
        "  elif classes[1] ==2:\n",
        "      classNames[1] = 'camel'\n",
        "  elif classes[1] ==3:\n",
        "      classNames[1] = 'car'\n",
        "  elif classes[1] ==4:\n",
        "      classNames[1] = 'helicopter'\n",
        "  elif classes[1] ==5:\n",
        "      classNames[1] = 'ladder'\n",
        "  elif classes[1] ==6:\n",
        "      classNames[1] = 'sofa'\n",
        "\n",
        "\n",
        "  tree = ET.parse(annpath + str(imageID) +'.xml')\n",
        "  root = tree.getroot()\n",
        "\n",
        "  disLabels = ['Very Close','Close','Far','Too Far']\n",
        "\n",
        "  distance = float(root.find('./distance').text)\n",
        "  distanceLabel = int(root.find('./distanceLabel').text)\n",
        "  # plt.title(f\" Actual Label:{disLabels[distanceLabel]},            Predicted Label:{disLabels[r['distance_label']]} \\n ActualDistance:{distance:.2f}, PredictedDistance:{r['distance']:.2f}\",loc='left', fontsize=9)\n",
        "\n",
        "  aboxes = []\n",
        "  for box in root.findall('.//bndbox'):\n",
        "    xmin = int(box.find('xmin').text)\n",
        "    ymin = int(box.find('ymin').text)\n",
        "    xmax = int(box.find('xmax').text)\n",
        "    ymax = int(box.find('ymax').text)\n",
        "    coors = [xmin, ymin, xmax, ymax]\n",
        "    aboxes.append(coors)\n",
        "\n",
        "  anames = []\n",
        "  for name in root.findall('.//name'):\n",
        "    anames.append(name.text)\n",
        "\n",
        "\n",
        "  ax = plt.gca()\n",
        "  rects=[]\n",
        "  for box in aboxes:\n",
        "    x1, y1, x2, y2 = box\n",
        "    width, height = x2 - x1, y2 - y1\n",
        "    rect = Rectangle((x1, y1), width, height, fill=False, color='green')\n",
        "    rects.append(rect)\n",
        "    ax.add_patch(rect)\n",
        "  for i, box in enumerate(r['rois']):\n",
        "    y1, x1, y2, x2 = box\n",
        "    width, height = x2 - x1, y2 - y1\n",
        "    rect = Rectangle((x1, y1), width, height, fill=False, color='red', linestyle='--')\n",
        "    rects.append(rect)\n",
        "    ax.annotate(classNames[i], (x1+height - 15, y1-6), color='red', fontsize=5, ha='center', va='center',**csfont)\n",
        "    ax.add_patch(rect)\n",
        "  # ax.legend([rects[0],rects[2]], ['ActualBox','PredictedBox'])\n",
        "  plt.text(5, 440,f\" Actual Label:{disLabels[distanceLabel]}, Predicted Label:{disLabels[r['distance_label']]}\\n \\n ActualDistance:{distance:.2f}, PredictedDistance:{r['distance']:.2f}\",\\\n",
        "           bbox=dict(fill=False, linewidth=0), fontsize=6,**csfont )\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC51as5c7U5T"
      },
      "source": [
        "# ***Modeling***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBGbvJGMettD",
        "outputId": "39f49121-2615-4b9a-89f1-4a4bff777d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  960\n",
            "IMAGE_META_SIZE                20\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [960 960   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1, 'd_output_loss': 1, 'd_output_lbl_loss': 1}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               10\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           MaskRCNN_config\n",
            "NUM_CLASSES                    8\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                20\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class myMaskRCNNConfig(Config):\n",
        "    # give the configuration a recognizable name\n",
        "    NAME = \"MaskRCNN_config\"\n",
        "\n",
        "    # set the number of GPUs to use along with the number of images\n",
        "    # per GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # number of classes (we would normally add +1 for the background)\n",
        "     # objects + BG\n",
        "    NUM_CLASSES = 8\n",
        "\n",
        "    # Number of training steps per epoch\n",
        "    STEPS_PER_EPOCH = 20\n",
        "\n",
        "    # Learning rate\n",
        "    LEARNING_RATE=0.001\n",
        "\n",
        "    # Skip detections with < 90% confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "\n",
        "    # setting Max ground truth instances\n",
        "    MAX_GT_INSTANCES=10\n",
        "\n",
        "    IMAGE_MAX_DIM = 960 #480 * 2\n",
        "\n",
        "    LOSS_WEIGHTS = {\n",
        "        \"rpn_class_loss\": 1.,\n",
        "        \"rpn_bbox_loss\": 1.,\n",
        "        \"mrcnn_class_loss\": 1.,\n",
        "        \"mrcnn_bbox_loss\": 1.,\n",
        "        \"mrcnn_mask_loss\": 1,\n",
        "        \"d_output_loss\": 1,\n",
        "        \"d_output_lbl_loss\": 1,\n",
        "    }\n",
        "\n",
        "\n",
        "config= myMaskRCNNConfig()\n",
        "config.display()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mr_model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir='./')"
      ],
      "metadata": {
        "id": "HCuZRIop32hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0fIaGiduXza"
      },
      "source": [
        "# ***Load Dataset***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6egUDNtXJqqC"
      },
      "outputs": [],
      "source": [
        "class Creating_Dataset(Dataset):\n",
        "    # load the dataset definitions\n",
        "    def load_dataset(self, dataset_dir, is_train=True):\n",
        "\n",
        "        # Add classes. We have only one class to add.\n",
        "        self.add_class(\"dataset\", 0, \"0\")\n",
        "        self.add_class(\"dataset\", 1, \"1\")\n",
        "        self.add_class(\"dataset\", 2, \"2\")\n",
        "        self.add_class(\"dataset\", 3, \"3\")\n",
        "        self.add_class(\"dataset\", 4, \"4\")\n",
        "        self.add_class(\"dataset\", 5, \"5\")\n",
        "        self.add_class(\"dataset\", 6, \"6\")\n",
        "\n",
        "\n",
        "\n",
        "        self.dataset_dir = dataset_dir\n",
        "        # define data locations for images and annotations\n",
        "        images_dir = dataset_dir + '/images/'\n",
        "        annotations_dir = dataset_dir + '/annots/'\n",
        "\n",
        "        # Iterate through all files in the folder to\n",
        "        #add class, images and annotaions\n",
        "        for filename in listdir(images_dir):\n",
        "\n",
        "            # extract image id\n",
        "            image_id = filename.split('.')[0]\n",
        "\n",
        "            # large\n",
        "            if is_train and (int(image_id) % 120) > 90:\n",
        "                continue\n",
        "            if not is_train and (int(image_id) % 120) < 90:\n",
        "                continue\n",
        "\n",
        "            # setting image file\n",
        "            img_path = images_dir + filename\n",
        "\n",
        "            # setting annotations file\n",
        "            ann_path = annotations_dir + image_id + '.xml'\n",
        "\n",
        "            # adding images and annotations to dataset\n",
        "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "\n",
        "    # extract bounding boxes from an annotation file\n",
        "    def extract_boxes(self, filename):\n",
        "\n",
        "        # load and parse the file\n",
        "        tree = ElementTree.parse(filename)\n",
        "        # get the root of the document\n",
        "        root = tree.getroot()\n",
        "        # extract each bounding box\n",
        "        boxes = list()\n",
        "        classes = list()\n",
        "        for box in root.findall('.//object'):\n",
        "            xmin = int(box.find('.//bndbox/xmin').text)\n",
        "            ymin = int(box.find('.//bndbox/ymin').text)\n",
        "            xmax = int(box.find('.//bndbox/xmax').text)\n",
        "            ymax = int(box.find('.//bndbox/ymax').text)\n",
        "            class_name = box.find('name').text\n",
        "            coors = [xmin, ymin, xmax, ymax]\n",
        "            boxes.append(coors)\n",
        "            classes.append(class_name)\n",
        "\n",
        "        # extract image dimensions\n",
        "        width = int(root.find('.//size/width').text)\n",
        "        height = int(root.find('.//size/height').text)\n",
        "        distance = float(root.find('./distance').text)\n",
        "\n",
        "        return boxes, width, height, classes\n",
        "\n",
        "    # load the masks for an image\n",
        "    \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "     \"\"\"\n",
        "    def load_mask(self, image_id):\n",
        "        # get details of image\n",
        "        info = self.image_info[image_id]\n",
        "\n",
        "        # define anntation  file location\n",
        "        path = info['annotation']\n",
        "\n",
        "        # load XML\n",
        "        boxes, w, h, classes = self.extract_boxes(path)\n",
        "\n",
        "        # create one array for all masks, each on a different channel\n",
        "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\n",
        "        # create masks\n",
        "        class_ids = list()\n",
        "        for i in range(len(boxes)):\n",
        "            box = boxes[i]\n",
        "            row_s, row_e = box[1], box[3]\n",
        "            col_s, col_e = box[0], box[2]\n",
        "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
        "            class_ids.append(self.class_names.index(classes[i]))\n",
        "        return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "    # load an image reference\n",
        "    #Return the path of the image.\"\"\"\n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        print(info)\n",
        "        return info['path']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hshm6FLOJtJR",
        "outputId": "cf934507-5616-4cc0-d529-b993a2a590fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 364\n",
            "Test: 120\n"
          ]
        }
      ],
      "source": [
        "# prepare train set\n",
        "train_set = Creating_Dataset()\n",
        "train_set.load_dataset('/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# prepare test/val set\n",
        "test_set = Creating_Dataset()\n",
        "test_set.load_dataset('/content/drive/MyDrive/Colab_Notebooks/Workspace/Objects-Dataset', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRQieO-JuqO3"
      },
      "source": [
        "# ***Loading Initial Weights***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb6oD9dIhTE1"
      },
      "outputs": [],
      "source": [
        "mr_model.load_weights('/content/drive/MyDrive/Colab_Notebooks/Workspace/MRCNN_Modified_Model/base_weights.h5', by_name=True)\n",
        "mr_model.load_weights('/content/drive/MyDrive/Colab_Notebooks/Workspace/MRCNN_Modified_Model/new_distance_weights.h5', by_name=True)\n",
        "mr_model.load_weights('/content/drive/MyDrive/Colab_Notebooks/Workspace/MRCNN_Modified_Model/new_cat_weights.h5', by_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaJViaWl-F9u"
      },
      "source": [
        "# ***Train Model***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "print(\"GPU:\", tf.config.list_physical_devices('GPU'))\n",
        "print(\"Num GPUs:\", len(physical_devices))"
      ],
      "metadata": {
        "id": "ex7eRMNXYL1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name():\n",
        "   print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "   print(\"Please install GPU version of TF\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrBOrScqXds7",
        "outputId": "4eaf53a8-193e-4e01-db15-cf2ee6eca014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please install GPU version of TF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n"
      ],
      "metadata": {
        "id": "AoSi2gRtXdhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "x3LIiz8VXdUG",
        "outputId": "5d340a8f-d26c-4ef4-bb96-14e398577f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eof_kSNln2w"
      },
      "outputs": [],
      "source": [
        "mr_model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=80, layers='heads')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT2WmscYO3o7"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/drive/MyDrive/Colab_Notebooks/Workspace/MRCNN-Modified-Model/my_weights3.h5'\n",
        "mr_model.keras_model.save_weights(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il_1eZK58vjG"
      },
      "outputs": [],
      "source": [
        "mr_model_inf = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir='./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBPsXuuB8vjH"
      },
      "outputs": [],
      "source": [
        "mr_model_inf.load_weights(model_path, by_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh8YcXHJxyEH"
      },
      "outputs": [],
      "source": [
        "#for test\n",
        "mr_model_inf.load_weights('/content/drive/MyDrive/Workspace/MRCNN-Modified-Model/base_weights.h5', by_name=True)\n",
        "mr_model_inf.load_weights('/content/drive/MyDrive/Workspace/MRCNN-Modified-Model/new_distance_weights.h5', by_name=True)\n",
        "mr_model_inf.load_weights('/content/drive/MyDrive/Workspace/MRCNN-Modified-Model/new_cat_weights.h5', by_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPAUbUvieDPE"
      },
      "outputs": [],
      "source": [
        "plot_model(mr_model.keras_model, '/content/drive/MyDrive/Workspace/MRCNN-Modified-Model/Model\\ Diagrams/train.svg', show_shapes=True)\n",
        "plot_model(mr_model_inf.keras_model, '/content/drive/MyDrive/Workspace/MRCNN-Modified-Model/Model\\ Diagrams/inf.svg', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmpHTSOYG_pe"
      },
      "source": [
        "# ***Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kAPF_7XEaKU"
      },
      "outputs": [],
      "source": [
        "visualize('00003')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMYwaJrYLP_6"
      },
      "outputs": [],
      "source": [
        "evaluate_model(test_set, mr_model_inf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5MkTMdFNRvKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}